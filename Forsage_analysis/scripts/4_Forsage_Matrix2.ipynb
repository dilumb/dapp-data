{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating Matrix-2 being reinvested in when 6th place is taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load balance sheet (see 1_Forsage_Ether_analysis.ipynb)\n",
    "\n",
    "curr_dir = os.getcwd()\n",
    "dir_path = os.path.dirname(curr_dir)\n",
    "\n",
    "file = \"balance\"\n",
    "path = os.path.join(dir_path, \"resources\", file + \".pkl\")\n",
    "balance = pickle.load(open(path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load log as dataframe (see 2_Forsage_log_sampling.ipynb)\n",
    "\n",
    "curr_dir = os.getcwd()\n",
    "dir_path = os.path.dirname(curr_dir)\n",
    "\n",
    "file = \"df_log\"\n",
    "path = os.path.join(dir_path, \"resources\", file + \".pkl\")\n",
    "df_log = pickle.load(open(path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sampled user addresses (see 2_Forsage_log_sampling.ipynb)\n",
    "\n",
    "curr_dir = os.getcwd()\n",
    "dir_path = os.path.dirname(curr_dir)\n",
    "\n",
    "loaded_data_list = [None, None, None]\n",
    "file_list = [\"pyramide_top\", \"pyramide_center_top\", \"pyramide_bottom\"]\n",
    "counter_list = [0, 1, 2]\n",
    "\n",
    "for i in counter_list:\n",
    "    path = os.path.join(dir_path, \"resources\", file_list[i] + \".pkl\")\n",
    "    loaded_data_list[i] = pickle.load(open(path, 'rb'))\n",
    "\n",
    "pyramide_top, pyramide_center_top, pyramide_bottom = loaded_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build restructured log\n",
    "df_restructured = df_log.copy()\n",
    "nm1_mask = df_log[\"concept:name\"] == \"New User-Place Matrix-1\"\n",
    "nm2_mask = df_log[\"concept:name\"] == \"New User-Place Matrix-2\"\n",
    "\n",
    "df_restructured.loc[nm1_mask, \"old_case:concept:name\"] = df_restructured[\"case:concept:name\"][nm1_mask]\n",
    "df_restructured.loc[nm2_mask, \"old_case:concept:name\"] = df_restructured[\"case:concept:name\"][nm2_mask]\n",
    "\n",
    "df_restructured.loc[nm1_mask, \"case:concept:name\"] = df_restructured[\"referrer\"][nm1_mask]\n",
    "df_restructured.loc[nm2_mask, \"case:concept:name\"] = df_restructured[\"referrer\"][nm2_mask]\n",
    "df_restructured.loc[nm1_mask, \"case:ident:piid\"] = df_restructured[\"referrer\"][nm1_mask]\n",
    "df_restructured.loc[nm2_mask, \"case:ident:piid\"] = df_restructured[\"referrer\"][nm2_mask]\n",
    "\n",
    "df_restructured.drop(df_restructured.index[~(nm2_mask)], inplace=True)\n",
    "df_restructured.reset_index(inplace=True)\n",
    "df_restructured.drop(columns=[\"index\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create smaller data sets for logs\n",
    "# Combine sign-ups is a matrix with reinvestment-events. That means concatenating the normal log and the restructured log.\n",
    "def log_cutter_restructured(pyramide_slice):\n",
    "    mask = df_restructured[\"case:concept:name\"].isin(pyramide_slice)\n",
    "    df_sublog = df_restructured[mask]\n",
    "    # add place to activity label\n",
    "    mask_place = df_sublog[\"place\"] != \"\"\n",
    "    df_sublog.loc[:, 'place'] = df_sublog['place'].apply(str).str[:-2]\n",
    "    df_sublog.iloc[(mask_place).values, 4] = df_sublog[[\"concept:name\", \"place\"]][mask_place].apply(\" : Place \".join, axis=1)\n",
    "    \n",
    "    # concatenate\n",
    "    mask_user = df_log[\"case:concept:name\"].isin(pyramide_slice)\n",
    "    df_restructured_concat = pd.concat([df_sublog, df_log[mask_user]], ignore_index=True, sort=False)\n",
    "    # set timestamp as such\n",
    "    df_restructured_concat['time:timestamp'] = pd.to_datetime(df_restructured_concat['time:timestamp'])\n",
    "    # sort\n",
    "    df_sorted = df_restructured_concat.sort_values(by=['time:timestamp', 'logIndex'])\n",
    "    #mask for M2\n",
    "    mask_new_referral = df_sorted['concept:name'].str.contains(\"New User-Place Matrix-2 : Place\")\n",
    "    mask_reinvest = df_sorted['concept:name'].str.contains(\"Reinvest Matrix-2\")\n",
    "    df_return = df_sorted[mask_new_referral | mask_reinvest]\n",
    "    df_return = df_return.fillna('')\n",
    "    \n",
    "    df_return.reset_index(inplace=True)\n",
    "    df_return.drop(columns=[\"index\"], inplace=True)\n",
    "    return df_return\n",
    "\n",
    "df_top_m2 = log_cutter_restructured(pyramide_top)\n",
    "df_center_top_m2 = log_cutter_restructured(pyramide_center_top)\n",
    "df_bottom_m2 = log_cutter_restructured(pyramide_bottom)\n",
    "\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "log_top_m2 = log_converter.apply(df_top_m2)\n",
    "log_center_top_m2 = log_converter.apply(df_center_top_m2)\n",
    "log_bottom_m2 = log_converter.apply(df_bottom_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify PM4Py to check directly-follows relation for TWO activities\n",
    "\n",
    "'''\n",
    "    This file is part of PM4Py (More Info: https://pm4py.fit.fraunhofer.de).\n",
    "\n",
    "    PM4Py is free software: you can redistribute it and/or modify -> THIS VERSION IS MODIFIED\n",
    "    it under the terms of the GNU General Public License as published by\n",
    "    the Free Software Foundation, either version 3 of the License, or\n",
    "    (at your option) any later version.\n",
    "\n",
    "    PM4Py is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    GNU General Public License for more details.\n",
    "\n",
    "    You should have received a copy of the GNU General Public License\n",
    "    along with PM4Py.  If not, see <https://www.gnu.org/licenses/>.\n",
    "'''\n",
    "from enum import Enum\n",
    "\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "from pm4py.objects.log.obj import EventLog\n",
    "from pm4py.util import exec_utils\n",
    "from pm4py.util.constants import PARAMETER_CONSTANT_ATTRIBUTE_KEY, PARAMETER_CONSTANT_RESOURCE_KEY, \\\n",
    "    PARAMETER_CONSTANT_TIMESTAMP_KEY\n",
    "from pm4py.util.xes_constants import DEFAULT_NAME_KEY, DEFAULT_RESOURCE_KEY, DEFAULT_TIMESTAMP_KEY\n",
    "import deprecation\n",
    "\n",
    "from typing import Optional, Dict, Any, Union, Tuple, List\n",
    "from pm4py.objects.log.obj import EventLog, EventStream, Trace\n",
    "\n",
    "\n",
    "class Parameters(Enum):\n",
    "    ATTRIBUTE_KEY = PARAMETER_CONSTANT_ATTRIBUTE_KEY\n",
    "    TIMESTAMP_KEY = PARAMETER_CONSTANT_TIMESTAMP_KEY\n",
    "    RESOURCE_KEY = PARAMETER_CONSTANT_RESOURCE_KEY\n",
    "    POSITIVE = \"positive\"\n",
    "    ENABLE_TIMESTAMP = \"enable_timestamp\"\n",
    "    TIMESTAMP_DIFF_BOUNDARIES = \"timestamp_diff_boundaries\"\n",
    "\n",
    "\n",
    "POSITIVE = Parameters.POSITIVE\n",
    "ENABLE_TIMESTAMP = Parameters.ENABLE_TIMESTAMP\n",
    "TIMESTAMP_DIFF_BOUNDARIES = Parameters.TIMESTAMP_DIFF_BOUNDARIES\n",
    "\n",
    "\n",
    "def timestamp_list_is_ge(a, b):\n",
    "    for i in range(len(a)):\n",
    "        if a[i] < b[i][0]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def timestamp_list_is_le(a, b):\n",
    "    for i in range(len(a)):\n",
    "        if a[i] > b[i][1]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "#@deprecation.deprecated('2.2.6', '3.0.0', 'please use pm4py.algo.filtering.log.ltl.ltl_checker.eventually_follows')\n",
    "\n",
    "\n",
    "\n",
    "def A_next_B(log: EventLog, A: str, B: str, parameters: Optional[Dict[Union[str, Parameters], Any]] = None) -> EventLog:\n",
    "    \"\"\"\n",
    "    Applies the A next B next C rule\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    log\n",
    "        Log\n",
    "    A\n",
    "        A attribute value\n",
    "    B\n",
    "        B attribute value\n",
    "    C\n",
    "        C attribute value\n",
    "    parameters\n",
    "        Parameters of the algorithm, including the attribute key and the positive parameter:\n",
    "        - If True, returns all the cases containing A, B and C and in which A was directly followed by B and B was directly followed by C\n",
    "        - If False, returns all the cases not containing A or B or C, or in which none instance of A was directly\n",
    "        followed by an instance of B and B was directly followed by C\n",
    "\n",
    "    Returns\n",
    "    ------------\n",
    "    filtered_log\n",
    "        Filtered log\n",
    "    \"\"\"\n",
    "    if parameters is None:\n",
    "        parameters = {}\n",
    "\n",
    "    log = log_converter.apply(log, variant=log_converter.Variants.TO_EVENT_LOG, parameters=parameters)\n",
    "\n",
    "    attribute_key = exec_utils.get_param_value(Parameters.ATTRIBUTE_KEY, parameters, DEFAULT_NAME_KEY)\n",
    "    positive = exec_utils.get_param_value(Parameters.POSITIVE, parameters, True)\n",
    "\n",
    "    new_log = EventLog(list(), attributes=log.attributes, extensions=log.extensions, classifiers=log.classifiers,\n",
    "                       omni_present=log.omni_present, properties=log.properties)\n",
    "\n",
    "    for trace in log:\n",
    "        found = True # here: found == conforming\n",
    "\n",
    "        # Check occurrences of A. Are they all As followed directly by B?\n",
    "        for i in range(len(trace) - 1):\n",
    "            if trace[i].get(attribute_key) == A:\n",
    "                if trace[i + 1].get(attribute_key) != B:\n",
    "                    found = False\n",
    "                    break\n",
    "        \n",
    "        if found:\n",
    "            if positive:\n",
    "                new_log.append(trace)\n",
    "        elif not positive:\n",
    "            new_log.append(trace)\n",
    "        \n",
    "    return new_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number non-conforming cases top: 822\n",
      "Number non-conforming cases center top: 2\n",
      "Number non-conforming cases bottom: 274\n"
     ]
    }
   ],
   "source": [
    "# compute diversions\n",
    "\n",
    "A = \"New User-Place Matrix-2 : Place 6\"\n",
    "B = \"Reinvest Matrix-2\"\n",
    "\n",
    "def compute_diversions(log):\n",
    "    new_log = A_next_B(log, A, B)\n",
    "    n_diversions = len(log)-len(new_log)\n",
    "    return n_diversions\n",
    "\n",
    "n_diversions_top = compute_diversions(log_top_m2)\n",
    "n_diversions_center_top = compute_diversions(log_center_top_m2)\n",
    "n_diversions_bottom = compute_diversions(log_bottom_m2)\n",
    "\n",
    "print(\"Number non-conforming cases top: \" + str(n_diversions_top))\n",
    "print(\"Number non-conforming cases center top: \" + str(n_diversions_center_top))\n",
    "print(\"Number non-conforming cases bottom: \" + str(n_diversions_bottom))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
